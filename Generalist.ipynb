{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7OEhqpKCuqOW"
   },
   "source": [
    "# Download and unpack files (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "IDpA7c_1Rn1V",
    "outputId": "37c47859-a538-4186-e3ba-013aff5a2f8c"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/0oz27mpojtbemyj/Generalist.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3034
    },
    "colab_type": "code",
    "id": "-IqUGjXgSt3s",
    "outputId": "0ed9eab1-1b63-4cc4-937d-8834e5a306aa"
   },
   "outputs": [],
   "source": [
    "!unzip Generalist.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "WLZEP7syUTRC",
    "outputId": "ed07cd45-e91e-42d9-92b6-b24a4001c8a0"
   },
   "outputs": [],
   "source": [
    "!pip install -r helpers/requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOV_t9eVuyuv"
   },
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzRXgEcPHkgd"
   },
   "outputs": [],
   "source": [
    "# Setup and instantiate the network model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from helpers import dataset as ds\n",
    "from helpers import datapreparation as dp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class Generalist(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_size):\n",
    "        super(Generalist, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers)#, dropout=0.25)\n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
    "        #self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.notes_decoder = nn.Linear(hidden_size, self.output_size)\n",
    "        #self.out1 = nn.ReLU()\n",
    "        self.out2 = nn.Sigmoid()\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self, tag=None):\n",
    "        return (Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)).cuda(),\n",
    "                Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)).cuda())\n",
    "\n",
    "    def forward(self, input_sequence, tag=None):\n",
    "        output, self.hidden = self.rnn(input_sequence, self.hidden)\n",
    "        #output = self.out1(output)\n",
    "        output = self.notes_decoder(output)\n",
    "        output = self.out2(output)\n",
    "        return output\n",
    "    \n",
    "dirpath = os.path.join('datasets', 'training', 'piano_roll_fs5')\n",
    "X = ds.pianoroll_dataset_batch(dirpath)\n",
    "input_size = X[0][0].size()[-1]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "\n",
    "model = Generalist(input_size, hidden_size, num_layers, batch_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghmfXK4ZqXfU"
   },
   "outputs": [],
   "source": [
    "# Instantiate hyperparameters\n",
    "#loss_func = nn.BCEWithLogitsLoss()\n",
    "loss_func = nn.BCELoss()\n",
    "#loss_func = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.1) \n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "\n",
    "#for song_x, tag, song_y in X:\n",
    "  #print(len(song_x), len(song_y))\n",
    "  #print((song_x[-1] - song_y[-2]).squeeze(1).cpu().data.numpy().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyjdJ7RfvoR4"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1061
    },
    "colab_type": "code",
    "id": "y-4de_KXxfq8",
    "outputId": "c8c44cf2-c987-4324-b1eb-fe6f29c8ad65"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.hidden = model.init_hidden()\n",
    "    output = model(X[0][0].cuda()).detach()\n",
    "    print(output[42])\n",
    "\n",
    "epochs = 32\n",
    "chunk_size = 32\n",
    "chunk_overlap = 8\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sum_loss = 0\n",
    "    chunk_count = 0\n",
    "    for input_sequence, tag, target_sequence in X:\n",
    "        i = 0\n",
    "        length = len(input_sequence)\n",
    "        while i < length:\n",
    "          j = min(i+chunk_size, length)\n",
    "          input_seq = input_sequence[i:j]\n",
    "          target_seq = target_sequence[i:j]\n",
    "          # Step 1. Remember that Pytorch accumulates gradients.\n",
    "          # We need to clear them out before each instance\n",
    "          model.zero_grad()\n",
    "\n",
    "          # Also, we need to clear out the hidden state of the LSTM,\n",
    "          # detaching it from its history on the last instance.\n",
    "          model.hidden = model.init_hidden()\n",
    "\n",
    "          # Step 3. Run our forward pass.\n",
    "          pred_seq = model(input_seq.cuda())\n",
    "\n",
    "          # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "          #  calling optimizer.step()\n",
    "          loss = loss_func(pred_seq.cuda(), target_seq.cuda())\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        \n",
    "          sum_loss += loss\n",
    "          chunk_count += 1\n",
    "          i += chunk_size-chunk_overlap\n",
    "    \n",
    "    print('loss: ' + str(sum_loss/(chunk_count)))\n",
    "    print(str(epoch+1) + '/' + str(epochs))#, end='\\r')\n",
    "    \n",
    "print(\"runtime: \", time.time() - start)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.hidden = model.init_hidden()\n",
    "    output = model(X[0][0].cuda()).detach()\n",
    "    print(output[42])\n",
    "    print(X[0][-1][42] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIY6LIsQ33Z8"
   },
   "source": [
    "# Save/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrQx2Qz_nTIb"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'GenState256_32_BCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jInS26fmoCMw"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('GenState256_16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zA07KZTp39vI"
   },
   "source": [
    "# Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "OrX2q_1axf8x",
    "outputId": "14695141-aedb-4b77-93e6-07ad3dc85976"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.hidden = model.init_hidden()\n",
    "    output = model(X[0][0].cuda())\n",
    "\n",
    "prediction = output.squeeze(1).cpu().data.numpy().T\n",
    "#prediction = np.array([np.pad(row, (22, 22), 'constant', constant_values=0) for row in prediction])\n",
    "#prediction /= prediction.max()\n",
    "prediction = prediction > 0.15\n",
    "dp.visualize_piano_roll(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmraZFAr6LwV"
   },
   "outputs": [],
   "source": [
    "dp.embed_play_v1(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXYYVfzyzbJe"
   },
   "outputs": [],
   "source": [
    "original = X[0][0].squeeze(1).cpu().data.numpy().T\n",
    "#song = np.array([np.pad(row, (22, 22), 'constant', constant_values=0) for row in original])\n",
    "dp.visualize_piano_roll(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vymj6_yZ6SsL"
   },
   "outputs": [],
   "source": [
    "dp.embed_play_v1(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bx6uw3MB4DdO"
   },
   "source": [
    "# Compose music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "colab_type": "code",
    "id": "CmYZDuLpo-nr",
    "outputId": "dd61e4cf-3b6e-4b44-f6e6-189ae3ce4ccc"
   },
   "outputs": [],
   "source": [
    "def compose(model, init_song, init_len, max_len):\n",
    "    composition = []\n",
    "    with torch.no_grad():\n",
    "        model.hidden = model.init_hidden()\n",
    "        for i in range(max_len+1):\n",
    "            if i <= init_len:\n",
    "                notes = init_song[0][i].unsqueeze(0)\n",
    "            else:\n",
    "                notes = output.ge(0.1).float() #/torch.max(output)\n",
    "\n",
    "            composition.append(notes.squeeze().cpu().data.numpy())\n",
    "            if i < max_len:\n",
    "              output = model(notes.cuda()).detach()\n",
    "\n",
    "    return np.array(composition).T\n",
    "\n",
    "composition = compose(model, X[0], 10, 1000)\n",
    "dp.visualize_piano_roll(composition)\n",
    "dp.embed_play_v1(composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9LD4nRQ8EaA"
   },
   "outputs": [],
   "source": [
    "model.hidden = model.init_hidden()\n",
    "dp.gen_music_seconds_smooth(model, X[0][0].cuda())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7OEhqpKCuqOW",
    "vUTc6PrR3zJu",
    "qIY6LIsQ33Z8"
   ],
   "name": "Generalist.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
